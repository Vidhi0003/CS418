{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "UIC CS 418, Fall 2025\n",
    "\n",
    "_According to the **Academic Integrity Policy** of this course, all work submitted for grading must be done individually, unless otherwise specified. While we encourage you to talk to your peers and learn from them, this interaction must be superficial with regard to all work submitted for grading. This means you cannot work in teams, you cannot work side-by-side, and you cannot submit someone else’s work (partial or complete) as your own. In particular, note that you are guilty of academic dishonesty if you extend or receive any kind of unauthorized assistance. Absolutely no transfer of program code between students is permitted (paper or electronic), and you may not solicit code from family, friends, or online forums. Other examples of academic dishonesty include emailing your program to another student, copying and pasting code from the internet, working in a group on a homework assignment, and allowing a tutor, TA, or another individual to write an answer for you. Academic dishonesty is unacceptable, and penalties range from failure to expulsion from the university; cases are handled via the official student conduct process described at https://dos.uic.edu/conductforstudents.shtml._\n",
    "\n",
    "_This homework may be completed in pairs. You may tag your teammate in Gradescope upon submission._\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59 pm CST on September 17, 2025. All parts of the assignments are due at the same time. If any segment of the assignment is submitted late, the late submission policy applies for the whole assignment. Instructions on how to submit it to Gradescope are given at the end of the notebook and should be followed carefully.\n",
    "\n",
    "## Part 1 (45% of HW1): Data processing with pandas \n",
    "\n",
    "\n",
    "In this homework, you will see examples of some commonly used data wrangling tools in Python. In particular, we aim to give you some familiarity with:\n",
    "\n",
    "* Slicing data frames\n",
    "* Filtering data\n",
    "* Grouped counts\n",
    "* Joining two tables\n",
    "* NA/Null values\n",
    "\n",
    "\n",
    "\n",
    "## Part 1: Practice (15%)\n",
    "\n",
    "This part of the homework is graded manually based on showing the correct outputs after executing each step.\n",
    "\n",
    "## Setup\n",
    "\n",
    "You need to execute each step (run each Cell), in order for the next ones to work. First, import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below produces the data frames used in the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes = pd.DataFrame(\n",
    "    data={'color': ['red', 'green', 'black', \n",
    "                    'blue', 'black', 'red'],\n",
    "          'first_seen_on': ['a', 'a', 'f', 'a', 'a', 'f'],\n",
    "          'first_season': [2, 1, 2, 3, 3, 1]},\n",
    "    index=['flash', 'arrow', 'vibe', \n",
    "           'atom', 'canary', 'firestorm']\n",
    ")\n",
    "\n",
    "identities = pd.DataFrame(\n",
    "    data={'ego': ['barry allen', 'oliver queen', 'cisco ramon',\n",
    "                  'ray palmer', 'sara lance', \n",
    "                  'martin stein', 'ronnie raymond'],\n",
    "          'alter-ego': ['flash', 'arrow', 'vibe', 'atom',\n",
    "                        'canary', 'firestorm', 'firestorm']}\n",
    ")\n",
    "\n",
    "teams = pd.DataFrame(\n",
    "    data={'team': ['flash', 'arrow', 'flash', 'legends', \n",
    "                   'flash', 'legends', 'arrow'],\n",
    "          'hero': ['flash', 'arrow', 'vibe', 'atom', \n",
    "                   'killer frost', 'firestorm', 'speedy']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Wrangling\n",
    "\n",
    "For the examples that follow, we will be using a toy data set containing information about superheroes in the Arrowverse.  In the `first_seen_on` column, `a` stands for Archer and `f`, Flash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "      <th>first_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrow</th>\n",
       "      <td>green</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atom</th>\n",
       "      <td>blue</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canary</th>\n",
       "      <td>black</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firestorm</th>\n",
       "      <td>red</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           color first_seen_on  first_season\n",
       "flash        red             a             2\n",
       "arrow      green             a             1\n",
       "vibe       black             f             2\n",
       "atom        blue             a             3\n",
       "canary     black             a             3\n",
       "firestorm    red             f             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ego</th>\n",
       "      <th>alter-ego</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barry allen</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oliver queen</td>\n",
       "      <td>arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cisco ramon</td>\n",
       "      <td>vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ray palmer</td>\n",
       "      <td>atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sara lance</td>\n",
       "      <td>canary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>martin stein</td>\n",
       "      <td>firestorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ronnie raymond</td>\n",
       "      <td>firestorm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ego  alter-ego\n",
       "0     barry allen      flash\n",
       "1    oliver queen      arrow\n",
       "2     cisco ramon       vibe\n",
       "3      ray palmer       atom\n",
       "4      sara lance     canary\n",
       "5    martin stein  firestorm\n",
       "6  ronnie raymond  firestorm"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>hero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flash</td>\n",
       "      <td>flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrow</td>\n",
       "      <td>arrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flash</td>\n",
       "      <td>vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>legends</td>\n",
       "      <td>atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flash</td>\n",
       "      <td>killer frost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>legends</td>\n",
       "      <td>firestorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arrow</td>\n",
       "      <td>speedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      team          hero\n",
       "0    flash         flash\n",
       "1    arrow         arrow\n",
       "2    flash          vibe\n",
       "3  legends          atom\n",
       "4    flash  killer frost\n",
       "5  legends     firestorm\n",
       "6    arrow        speedy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice and Dice\n",
    "\n",
    "#### Column selection by label\n",
    "To select a column of a `DataFrame` by column label, the safest and fastest way is to use the `.loc` method. General usage looks like `frame.loc[rowname,colname]`. (Reminder that the colon `:` means \"everything\").  For example, if we want the `color` column of the `heroes` data frame, we would use :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flash          red\n",
       "arrow        green\n",
       "vibe         black\n",
       "atom          blue\n",
       "canary       black\n",
       "firestorm      red\n",
       "Name: color, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.loc[:, 'color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting multiple columns is easy. You just need to supply a list of column names. Here we select the color and value columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrow</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atom</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canary</th>\n",
       "      <td>black</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firestorm</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           color  first_season\n",
       "flash        red             2\n",
       "arrow      green             1\n",
       "vibe       black             2\n",
       "atom        blue             3\n",
       "canary     black             3\n",
       "firestorm    red             1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.loc[:, ['color', 'first_season']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While .loc is invaluable when writing production code, it may be a little too verbose for interactive use. One recommended alternative is the [] method, which takes on the form frame['colname']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flash        a\n",
       "arrow        a\n",
       "vibe         f\n",
       "atom         a\n",
       "canary       a\n",
       "firestorm    f\n",
       "Name: first_seen_on, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes['first_seen_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row Selection by Label\n",
    "\n",
    "Similarly, if we want to select a row by its label, we can use the same .loc method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "      <th>first_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       color first_seen_on  first_season\n",
       "flash    red             a             2\n",
       "vibe   black             f             2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.loc[['flash', 'vibe'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want all the columns returned, we can, for brevity, drop the colon without issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "      <th>first_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       color first_seen_on  first_season\n",
       "flash    red             a             2\n",
       "vibe   black             f             2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.loc[['flash', 'vibe']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Selection by Label\n",
    "\n",
    "More generally you can slice across both rows and columns at the same time.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrow</th>\n",
       "      <td>green</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atom</th>\n",
       "      <td>blue</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       color first_seen_on\n",
       "flash    red             a\n",
       "arrow  green             a\n",
       "vibe   black             f\n",
       "atom    blue             a"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.loc['flash':'atom', :'first_seen_on']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection by Integer Index\n",
    "\n",
    "If you want to select rows and columns by position, the Data Frame has an analogous `.iloc` method for integer indexing. Remember that Python indexing starts at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <td>red</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrow</th>\n",
       "      <td>green</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vibe</th>\n",
       "      <td>black</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atom</th>\n",
       "      <td>blue</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       color first_seen_on\n",
       "flash    red             a\n",
       "arrow  green             a\n",
       "vibe   black             f\n",
       "atom    blue             a"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes.iloc[:4,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering with boolean arrays\n",
    "\n",
    "Filtering is the process of removing unwanted material.  In your quest for cleaner data, you will undoubtedly filter your data at some point: whether it be for clearing up cases with missing values, culling out fishy outliers, or analyzing subgroups of your data set.  For example, we may be interested in characters that debuted in season 3 of Archer.  Note that compound expressions have to be grouped with parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>first_seen_on</th>\n",
       "      <th>first_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atom</th>\n",
       "      <td>blue</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canary</th>\n",
       "      <td>black</td>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        color first_seen_on  first_season\n",
       "atom     blue             a             3\n",
       "canary  black             a             3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heroes[(heroes['first_season']==3) & (heroes['first_seen_on']=='a')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Solving Strategy\n",
    "We want to highlight the strategy for filtering to answer the question above:\n",
    "\n",
    "* **Identify the variables of interest**\n",
    "    * Interested in the debut: `first_season` and `first_seen_on`\n",
    "* **Translate the question into statements one with True/False answers**\n",
    "    * Did the hero debut on Archer? $\\rightarrow$ The hero has `first_seen_on` equal to `a`\n",
    "    * Did the hero debut in season 3? $\\rightarrow$ The hero has `first_season` equal to `3`\n",
    "* **Translate the statements into boolean statements**\n",
    "    * The hero has `first_seen_on` equal to `a` $\\rightarrow$ `hero['first_seen_on']=='a'`\n",
    "    * The hero has `first_season` equal to `3` $\\rightarrow$ `heroes['first_season']==3`\n",
    "* **Use the boolean array to filter the data**\n",
    "\n",
    "Note that compound expressions have to be grouped with parentheses.\n",
    "\n",
    "For your reference, some commonly used comparison operators are given below.\n",
    "\n",
    "Symbol | Usage      | Meaning \n",
    "------ | ---------- | -------------------------------------\n",
    "==   | a == b   | Does a equal b?\n",
    "<=   | a <= b   | Is a less than or equal to b?\n",
    "\\>=   | a >= b   | Is a greater than or equal to b?\n",
    "<    | a < b    | Is a less than b?\n",
    "&#62;    | a &#62; b    | Is a greater than b?\n",
    "~    | ~p       | Returns negation of p\n",
    "&#124; | p &#124; q | p OR q\n",
    "&    | p & q    | p AND q\n",
    "^  | p ^ q | p XOR q (exclusive or)\n",
    "\n",
    "An often-used operation missing from the above table is a test-of-membership.  The `Series.isin(values)` method returns a boolean array denoting whether each element of `Series` is in `values`.  We can then use the array to subset our data frame. For example, if we wanted to see which rows of `heroes` had values in $\\{1,3\\}$, we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes[heroes['first_season'].isin([1,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in both examples above, the expression in the brackets evaluates to a boolean series.  The general strategy for filtering data frames, then, is to write an expression of the form `frame[logical statement]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Rows\n",
    "\n",
    "To count the number of instances of a value in a `Series`, we can use the `value_counts` method.  Below we count the number of instances of each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes['color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated analysis might involve counting the number of instances a tuple appears.  Here we count $(color,value)$ tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.groupby(['color', 'first_season']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a series that has been multi-indexed.  We'll eschew this topic for now.  To get a data frame back, we'll use the `reset_index` method, which also allows us to simulataneously name the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes.groupby(['color', 'first_season']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Tables on One Column\n",
    "\n",
    "Suppose we have another table that classifies superheroes into their respective teams.  Note that `canary` is not in this data set and that `killer frost` and `speedy` are additions that aren't in the original `heroes` set.\n",
    "\n",
    "For simplicity of the example, we'll convert the index of the `heroes` data frame into an explicit column called `hero`.  A careful examination of the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) will reveal that joining on a mixture of the index and columns is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes['hero'] = heroes.index\n",
    "heroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join\n",
    "\n",
    "The inner join below returns rows representing the heroes that appear in both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='inner', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left and right join\n",
    "The left join returns rows representing heroes in the `heroes` (\"left\") data frame, augmented by information found in the `teams` data frame.  Its counterpart, the right join, would return heroes in the `teams` data frame.  Note that the `team` for hero `canary` is an `NaN` value, representing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='left', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer join\n",
    "\n",
    "An outer join on `hero` will return all heroes found in both the left and right data frames.  Any missing values are filled in with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, teams, how='outer', on='hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More than one match?\n",
    "\n",
    "If the values in the columns to be matched don't uniquely identify a row, then a cartesian product is formed in the merge.  For example, notice that `firestorm` has two different egos, so information from `heroes` had to be duplicated in the merge, once for each ego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(heroes, identities, how='inner', \n",
    "         left_on='hero', right_on='alter-ego')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "There are a multitude of reasons why a data set might have missing values.  The current implementation of Pandas uses the numpy NaN to represent these null values (older implementations even used `-inf` and `inf`).  Future versions of Pandas might implement a true `null` value---keep your eyes peeled for this in updates!  More information can be found [http://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html](http://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html)\n",
    "\n",
    "Because of the specialness of missing values, they merit their own set of tools.  Here, we will focus on detection.  For replacement, see the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.nan\n",
    "y = pd.merge(heroes, teams, how='outer', on='hero')['first_season']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if a value is null, we use the `isnull()` method for series and data frames.  Alternatively, there is a `pd.isnull()` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.isnull() # Will throw an error since x is neither a series nor a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since filtering out missing data is such a common operation, Pandas also has conveniently included the analogous `notnull()` methods and function for improved human readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Questions (30%)\n",
    "\n",
    "The problems below are based on an article that appeared in https://chi.streetsblog.org/2022/04/25/data-analysis-found-cta-has-only-been-running-about-half-its-schedule-blue-line-runs\n",
    "\n",
    "In short, during 2022, the train service run by CTA was somewhat irregular, especially since they were doing maintenance work. As mentioned in the article, Fabio Göttlicher, a resident of Chicago decided to record arrival times of the blue line at a particular train stop. We will use more recent data to calculate delays at this train stop. This data is given to you as 7 json files. If interested, you can see how you can get such data by quering the CTA for real time feed in Fabio Göttlicher's website at https://github.com/FabioCZ/dude-wheres-my-train/tree/main\n",
    "\n",
    "The first three parts of starter code below provides the skeleton for processing one json file with which you can calculate the delays. \n",
    "\n",
    "In the last part, you will have to repeat the calculation for the full week and calculate weekly variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore the warnings.\n",
    "\n",
    "# load the json file to get arrival and schedule for the day\n",
    "arrival_data = pd.read_json('20240801.json')\n",
    "\n",
    "# show the first few rows, by default 5\n",
    "#print(arrival_data.head() )\n",
    "print(arrival_data.shape)\n",
    "\n",
    "#let's look at the columns\n",
    "print(arrival_data.columns)\n",
    "\n",
    "#get arrivals and scheduled columns -- all actual arrival and scheduled times are stored in these two dataframe columns\n",
    "arrivals_info = arrival_data.loc[:,'arrivals']\n",
    "schedule_info = arrival_data.loc[:,'scheduled']\n",
    "\n",
    "print(arrivals_info.head())\n",
    "print(schedule_info.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1 (8% credit)\n",
    "Data Preprocessing to get scheduled and arrival times from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4%credit\n",
    "# In this cell we will extract schedule as a list\n",
    "\n",
    "#allDepartures column has all the scheduled information\n",
    "num_of_scheduled = len(schedule_info.iloc[1][\"allDepartures\"]) #change 1 to 0 to get schedule of 30111 or a particular direction (northbound)\n",
    "print(num_of_scheduled)\n",
    "\n",
    "#to get a particular scheduled time, we can use iloc\n",
    "print(schedule_info.iloc[1][\"allDepartures\"][num_of_scheduled-5]) #prints the 5th from last entry\n",
    "#observe that schedules are already stored in HH:MM:SS format, so no preprocessing required\n",
    "\n",
    "#insert to code create a list containing all the times when trains are scheduled on the day\n",
    "scheduled_times_list = [YOUR CODE HERE]\n",
    "scheduled_times = pd.DataFrame(scheduled_times_list)\n",
    "\n",
    "print(num_of_scheduled==scheduled_times.shape[0]) #should evaluate to True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4%credit\n",
    "# In this cell we will extract actual arrivals as a list\n",
    "\n",
    "#it looks like all the arrivals are stored in the first and second rows\n",
    "num_of_arrivals= len(arrivals_info.iloc[1]) #change 1 to 0 to get arrivals of 30111 or a particular direction (northbound) \n",
    "print(num_of_arrivals) # gives number of arrival time in the direction\n",
    "print(arrivals_info.iloc[1][num_of_arrivals-1][\"arrival\"])#extract last entry in the series\n",
    "\n",
    "## insert code to extract time in the string, that is, have to extract substring between 'T' and '-' \n",
    "[YOUR CODE HERE]\n",
    "\n",
    "arrival_time = \"23:49:41\" \n",
    "print(arrival_time == \"23:49:41\" ) #time of arrival\n",
    "#output should be in HH:MM:SS format like 23:49:31 for the last entry as above\n",
    "print(time)\n",
    "\n",
    "## insert code to exact times of all arrivals on a day. Store in a list and convert to series or dataframe called arrival_times\n",
    "arrival_times_list = []\n",
    "[YOUR CODE HERE]\n",
    "\n",
    "arrival_times = pd.DataFrame(arrival_times_list)\n",
    "print(num_of_arrivals==arrival_times.shape[0]) #should evaluate to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So percent run is\n",
    "print('Efficiency of the train system is:',len(arrivals_info.iloc[1])/len(schedule_info.iloc[1][\"allDepartures\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 (6% credit)\n",
    "Since the departure and arrival are given in HH:MM:SS format, we will write two helper functions to convert to minutes.  Write two functions, `extract_hour` and `extract_mins` that converts this format to hours and minutes, respectively. Hint: You may want to use modular arithmetic and integer division. Keep in mind that the data has not been cleaned and you need to check whether the extracted values are valid. Replace all the invalid values with `NaN`. The documentation for `pandas.Series.where` provided [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.where.html) should be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def extract_hour(time):\n",
    "    \"\"\"\n",
    "    Extracts hour information from military time\n",
    "    \n",
    "    Args: \n",
    "        time (float64): series of time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): series of input dimension with hour information.  \n",
    "          Should only take on integer values in 0-23\n",
    "    \"\"\"\n",
    "    [YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write code to test your extract_hour function here and execute it\n",
    "# HINT: See tests_sample_part1/tests.py\n",
    "[YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def extract_mins(time):\n",
    "    \"\"\"\n",
    "    Extracts minute information from military time\n",
    "    \n",
    "    Args: \n",
    "        time (float64): series of time given in military format.  \n",
    "          Takes on values in 0.0-2359.0 due to float64 representation.\n",
    "    \n",
    "    Returns:\n",
    "        array (float64): series of input dimension with minute information.  \n",
    "          Should only take on integer values in 0-59\n",
    "    \"\"\"\n",
    "    [YOUR CODE HERE]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write code to test your extract_mins function here and execute it\n",
    "# HINT: See tests_sample_part1/tests.py\n",
    "[YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def convert_to_minofday(time):\n",
    "    \"\"\"\n",
    "    Converts HH:MM time to minute of day\n",
    "    \n",
    "    Args:\n",
    "        time: series of time given as strings in HH:MM:SS format.  \n",
    "          \n",
    "    \n",
    "    Returns:\n",
    "        array (float64): series of input dimension with minute of day\n",
    "    \n",
    "    Example: 13:03 is converted to 783.0\n",
    "    \"\"\"\n",
    "    [YOUR CODE HERE]\n",
    "    \n",
    "    \n",
    "# Test your code\n",
    "ser = pd.Series(['13:03:00', '12:00:00', '24:00:00'])\n",
    "convert_to_minofday(ser)\n",
    "# 0    783.0\n",
    "# 1    720.0\n",
    "# 2      NaN\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 (6% credit)\n",
    "\n",
    "Before we can calculate delays, we need one more important function to write. Notice that arrival times and departure times are given as two lists or dataframes. Our first task is to relate them so that each entry in the arrivals with a corresponding scheduled times. We will assume that clearly num_of_arrivals <= num_scheduled as is the case in these files (check this yourself!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3%credit\n",
    "def assigned_scheduled_times(arrival_times, scheduled_times):\n",
    "    \"\"\"\n",
    "    Calculates delay times y - x\n",
    "    \n",
    "    Args:\n",
    "        arrival_times: series of scheduled times \n",
    "        scheduled_times: series of actual arrival times\n",
    "    \n",
    "    Returns:\n",
    "        arrival_scheduled_times: pandas dataframe with two columns viz., arrival times and corresponding scheduled time\n",
    "    \"\"\"\n",
    "    actual = [YOUR CODE HERE]\n",
    "\n",
    "    # insert code to find the closest scheduled time for each arrival time in arrival_times\n",
    "    scheduled = [YOUR CODE HERE]\n",
    "    [YOUR CODE HERE]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3% credit\n",
    "def calc_delay(assigned_scheduled_times):\n",
    "    \"\"\"\n",
    "    Calculates delay times y - x\n",
    "    \n",
    "    Args:\n",
    "        assigned_scheduled_times: pandas dataframe with two columns viz., arrival times and corresponding scheduled time\n",
    "    \n",
    "    Returns: \n",
    "        pandas series of input dimension with delay time\n",
    "    \"\"\"\n",
    "    \n",
    "    scheduled = [YOUR CODE HERE]\n",
    "    actual = [YOUR CODE HERE]\n",
    "    \n",
    "    [YOUR CODE HERE]\n",
    "    \n",
    "#Test your code\n",
    "sched = pd.Series([1303, 1210], dtype='float64')\n",
    "actual = pd.Series([1304, 1215], dtype='float64')\n",
    "calc_delay(pd.concat([sched, actual], axis=1))\n",
    "# 0    1.0\n",
    "# 1    5.0\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4 (10% credit)\n",
    "\n",
    "Once you have figured out the data preprocessing to obtain actual arrival and scheduled times of the train from one json, you can now write a function to extract them for all the 7 days (or json files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3%credit\n",
    "# Function to extract scheduled and actual arrival data for all 7 json files\n",
    "[YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3% credit\n",
    "### write code to test your functions here by calculating delay between `sched_dep_time` and `actual_dep_time` for each direction. \n",
    "### your printed results should show the values of the following two variables\n",
    "[YOUR CODE HERE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average delay for each day of the week and the weekly variance and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate \n",
    "#   1 (2%credit). the average delay for each day  -- 7 numbers for each direction,  \n",
    "#   2 (2%credit). the variance between them the 7 numbers, and  \n",
    "#   3. store in a dataframe with 8 rows (last row for variance) and 2 columns, and save in a csv file for submission\n",
    "[YOUR CODE HERE]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (45% of HW 1): Web scraping and data collection \n",
    "\n",
    "Here, you will practice collecting and processing data in Python. By the end of this exercise hopefully you should look at the wonderful world wide web without fear, comforted by the fact that anything you can see with your human eyes, a computer can see with its computer eyes. In particular, we aim to give you some familiarity with:\n",
    "\n",
    "* Using HTTP to fetch the content of a website\n",
    "* HTTP Requests (and lifecycle)\n",
    "* RESTful APIs\n",
    "    * Authentication (OAuth)\n",
    "    * Pagination\n",
    "    * Rate limiting\n",
    "* JSON vs. HTML (and how to parse each)\n",
    "* HTML traversal (CSS selectors)\n",
    "\n",
    "Since everyone loves food (presumably), the ultimate end goal of this homework will be to acquire the data to answer some questions and hypotheses about the restaurant scene in Chicago (which we will get to later). We will download __both__ the metadata on restaurants in Chicago from the Yelp API and with this metadata, retrieve the comments/reviews and ratings from users on restaurants.\n",
    "\n",
    "\n",
    "### Library Documentation\n",
    "\n",
    "For solving this part, you need to look up online documentation for the Python packages you will use:\n",
    "\n",
    "* Standard Library: \n",
    "    * [io](https://docs.python.org/3/library/io.html)\n",
    "    * [time](https://docs.python.org/3/library/time.html)\n",
    "    * [json](https://docs.python.org/3/library/json.html)\n",
    "\n",
    "* Third Party\n",
    "    * [requests](http://docs.python-requests.org/en/master/)\n",
    "    * [Beautiful Soup (version 4)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, time, json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication and working with APIs\n",
    "\n",
    "There are various authentication schemes that APIs use, listed here in relative order of complexity:\n",
    "\n",
    "* No authentication\n",
    "* [HTTP basic authentication](https://en.wikipedia.org/wiki/Basic_access_authentication)\n",
    "* Cookie based user login\n",
    "* OAuth (v1.0 & v2.0, see this [post](http://stackoverflow.com/questions/4113934/how-is-oauth-2-different-from-oauth-1) explaining the differences)\n",
    "* API keys\n",
    "* Custom Authentication\n",
    "\n",
    "For the IMDb example below (**Q2.1**), since it is a publicly visible page we did not need to authenticate. HTTP basic authentication isn't too common for consumer sites/applications that have the concept of user accounts (like Facebook, LinkedIn, Twitter, etc.) but is simple to setup quickly and you often encounter it on with individual password protected pages/sites. \n",
    "\n",
    "Cookie based user login is what the majority of services use when you login with a browser (i.e. username and password). Once you sign in to a service like Facebook, the response stores a cookie in your browser to remember that you have logged in (HTTP is stateless). Each subsequent request to the same domain (i.e. any page on `facebook.com`) also sends the cookie that contains the authentication information to remind Facebook's servers that you have already logged in.\n",
    "\n",
    "Many REST APIs however use OAuth (authentication using tokens) which can be thought of a programmatic way to \"login\" _another_ user. Using tokens, a user (or application) only needs to send the login credentials once in the initial authentication and as a response from the server gets a special signed token. This signed token is then sent in future requests to the server (in place of the user credentials).\n",
    "\n",
    "A similar concept common used by many APIs is to assign API Keys to each client that needs access to server resources. The client must then pass the API Key along with _every_ request it makes to the API to authenticate. This is because the server is typically relatively stateless and does not maintain a session between subsequent calls from the same client. Most APIs (including Spotify) allow you to pass the API Key via a special HTTP Header: `Authorization: Bearer <API_KEY>`. Check out the [docs](https://developer.spotify.com/documentation/web-api/concepts/authorization) for more information.\n",
    "\n",
    "\n",
    "### Question 2.1: Basic HTTP Requests w/o authentication (5%)\n",
    "\n",
    "First, let's do the \"hello world\" of making web requests with Python to get a sense for how to programmatically access web pages: an (unauthenticated) HTTP GET to download a web page.\n",
    "\n",
    "Fill in the funtion to use `requests` to download and return the raw HTML content of the URL passed in as an argument. As an example try the following IMDb page to retrieve titles and descriptions of top 250 movies: [https://www.imdb.com/chart/top/](https://www.imdb.com/chart/top/)\n",
    "\n",
    "Your function should return a string of: `<text>`. \n",
    "\n",
    "(Hint: look at the **Library documentation** listed earlier to see how `requests` should work.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    [YOUR CODE HERE]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "imdb_url = 'https://www.imdb.com/chart/top/'\n",
    "imdb_data = retrieve_html(imdb_url)\n",
    "print(imdb_data[:1000])\n",
    "# <!DOCTYPE html><html lang=\"en-US\" xmlns:og=\"http://opengraphprotocol.org/schema/\" xmlns:fb=\"http://www.facebook.com/2008/fbml\"><head><meta charSet=\"utf-8\"/>..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3% credit\n",
    "def parse_imdb(imdb_data):\n",
    "    \"\"\"\n",
    "    Return the movie lists from imdb top chart URL.\n",
    "\n",
    "    Args:\n",
    "        raw_html (string): \n",
    "\n",
    "    Returns:\n",
    "        movies (list): the list of movies with Title, Description and Rating.\n",
    "    \n",
    "        Example:\n",
    "        movies = [\n",
    "        {\n",
    "            'Title': 'The Shawshank Redemption',\n",
    "            'Description': 'A Maine banker convicted of the murder of his wife and her lover...',\n",
    "            'Rating': 9.3,\n",
    "        },\n",
    "        {\n",
    "            'Title': 'The Godfather',\n",
    "            'Description': 'Don Vito Corleone, head of a mafia family, decides to hand over his empire...',\n",
    "            'Rating': 9.2,\n",
    "\n",
    "        },\n",
    "            # ... more\n",
    "        ]\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    [YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if imdb_data:\n",
    "    movies = parse_imdb(imdb_data)\n",
    "    for movie in movies[:3]:\n",
    "        print(f\"Title: {movie['Title']}\")\n",
    "        print(f\"Description: {movie['Description']}\")\n",
    "        print(f\"Rating: {movie['Rating']}\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage content.\")\n",
    "\n",
    "# Example outputs\n",
    "# Title: The Shawshank Redemption\n",
    "# Description: A banker convicted of uxoricide forms a friendship over a quarter century with a hardened convict, while maintaining his innocence and trying to remain hopeful through simple compassion.\n",
    "# Rating: 9.3\n",
    "# Title: The Godfather\n",
    "# Description: The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.\n",
    "# Rating: 9.2\n",
    "# Title: The Dark Knight\n",
    "# Description: When a menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman, James Gordon and Harvey Dent must work together to put an end to the madness.\n",
    "# Rating: 9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now while this example might have been fun, we haven't yet done anything more than we could with a web browser. To really see the power of programmatically making web requests we will need to interact with an API. For the rest of this lab we will be working with the [Spotify Web API](https://developer.spotify.com/documentation/web-api). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify Web API Access\n",
    "\n",
    "The reasons for using the Spotify Web API are threefold:\n",
    "\n",
    "1. Incredibly Rich Dataset:\n",
    "    * Track and Artist Data: detailed information about tracks and artists.\n",
    "    * Genre and Popularity Trends: Analyze trends in music genres and track popularity over time.\n",
    "    * Audio Features: Analyze tracks based on audio features like tempo, key, and more.\n",
    "    * Personal Relevance: the Spotify API enables you to find data that resonates with your personal interests and preferences, making the analysis more engaging and insightful.\n",
    "2. Well-Documented API: The Spotify Web API [Documentation](https://developer.spotify.com/documentation/web-api) provides thorough examples and guides to help you get started with API requests, handling responses, and understanding the rich dataset available through Spotify.\n",
    "\n",
    "\n",
    "To access the Spotify API, you will need to perform a few steps. Like many other platforms, Spotify uses authentication and rate limiting to control access to its data. This ensures fair usage and compliance with Spotify's policies. The first step (even before making any request) is to set up a Spotify Developer account and obtain API credentials.\n",
    "\n",
    "1. Create a [Spotify](https://accounts.spotify.com/en/login) account (if you do not have one already)\n",
    "2. Log into the [dashboard](https://developer.spotify.com/dashboard) using your Spotify account. \n",
    "2. Generate API keys (if you haven't already). Create an app and select \"Web API\" for the question asking which APIs are you planning to use. Once you have created your app, you will have access to the app credentials. These will be required for API authorization to obtain an access token.\n",
    "\n",
    "Now that we have our accounts setup we can start making requests! \n",
    "\n",
    "\n",
    "### Question 2.2: Authenticated HTTP Request with the Spotify Web API (12%)\n",
    "\n",
    "First, store your Spotify credentials in a local file (kept out of version control) which you can read in to authenticate with the API. This file can be any format/structure since you will fill in the function stub below.\n",
    "\n",
    "For example, you may want to store your key in a file called `spotify_api_key.json` (run in terminal):\n",
    "```bash\n",
    "echo '{\"client_id\": \"your_client_id\", \"client_secret\": \"your_client_secret_key\"}' > spotify_api_key.json\n",
    "```\n",
    "\n",
    "**KEEP THE API KEY FILE PRIVATE AND OUT OF VERSION CONTROL (and definitely do not submit them to Gradescope!)**\n",
    "\n",
    "You can then read from the file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1% credit\n",
    "with open('spotify_api_key.json', 'r') as file:\n",
    "    credentials = json.load(file)\n",
    "    \n",
    "    # Extract the credentials\n",
    "    client_id = credentials['client_id']\n",
    "    client_secret = credentials['client_secret']\n",
    "    print(client_id, client_secret)\n",
    "    # verify your credentials are correct\n",
    "# DO NOT FORGET TO CLEAR THE OUTPUT TO KEEP YOUR API KEY PRIVATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1% credit\n",
    "def read_api_key(filepath):\n",
    "    \"\"\"\n",
    "    Read the Spotify API Keys from file.\n",
    "    \n",
    "    Args:\n",
    "        filepath (string): File containing API Keys\n",
    "    Returns:\n",
    "        client_id (string): Your client id\n",
    "        client_secret (string): Your client secret\n",
    "    \"\"\"\n",
    "    \n",
    "    # feel free to modify this function if you are storing the API Key differently\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now authenticate and get access token for future search. \n",
    "\n",
    "**Hint: read Authorization Code Flow [docs](https://developer.spotify.com/documentation/web-api/tutorials/code-flow).** \n",
    "1. Send a POST request to the /api/token endpoint.\n",
    "2. Parse the response json to get access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def access_spotify(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Authenticates the user and retrieves the bearer token required for API requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    auth_url = 'https://accounts.spotify.com/api/token'\n",
    "    auth_header = [YOUR CODE HERE]\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Basic {auth_header}',\n",
    "    }\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    \n",
    "    response = [YOUR CODE HERE]\n",
    "    access_token = [YOUR CODE HERE]\n",
    "    \n",
    "    return access_token\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# DO NOT FORGET TO CLEAR THE OUTPUT TO KEEP YOUR API KEY PRIVATE\n",
    "\n",
    "access_token = access_spotify(client_id, client_secret)\n",
    "print(f\"Authenticated with token: {access_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Spotify API, fill in the following function stub to make an authenticated request to the [Search Endpoint](https://developer.spotify.com/documentation/web-api/reference/search). Once you have the access token, you can use it to search for content (Tracks, Artists, or Albums) on Spotify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4% credit    \n",
    "def spotify_search_params(client_id, client_secret, **kwargs):\n",
    "    \"\"\"\n",
    "    Construct url, headers and params. Reference API docs (link above) to use the arguments\n",
    "    \"\"\"\n",
    "    # What is the url endpoint for search?\n",
    "    url = [YOUR CODE HERE]\n",
    "    # How is Authentication performed? Hint: use access_token from function of access_spotify\n",
    "    headers = [YOUR CODE HERE]\n",
    "    # SPACES in url is problematic. How should you handle queries with field filters?\n",
    "    query = [YOUR CODE HERE]\n",
    "    # Include keyword arguments in params dictionary\n",
    "    params = [YOUR CODE HERE]\n",
    "    \n",
    "    return url, headers, params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: `**kwargs` represent keyword arguments that are passed to the function. For example, if you called the function `spotify_search_params(client_id, client_secret, artist=\"Taylor Swift\", track=\"Lover\", type=\"track\", limit=10, offset=0))`. The arguments `client_id` and `client_secret` are called *positional arguments* and key-value pair arguments are called **keyword arguments**. Your `kwargs` variable will be a python dictionary with those keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "url, headers, params = spotify_search_params(\n",
    "    client_id, client_secret, \n",
    "    artist=\"Taylor Swift\", \n",
    "    track=\"Lover\", \n",
    "    type=\"track\",\n",
    "    limit=5,\n",
    "    offset=0\n",
    ")\n",
    "url, headers, params\n",
    "# ('https://<hidden_url_check_search_endpoint_docs_to_get_answer>',\n",
    "#  {'Authorization': 'Bearer your_access_token'},\n",
    "#  {'q': 'artist:Taylor Swift track:Lover', 'type': 'track', 'limit': 5,'offset':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `spotify_search_params(client_id, client_secret, **kwargs)` to actually search album/track/artist from Spotify API. Most of the code is provided to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2% credit\n",
    "def api_get_request(url, headers, params):\n",
    "    \"\"\"\n",
    "    Send a HTTP GET request and return a json response \n",
    "    \n",
    "    Args:\n",
    "        url (string): API endpoint url\n",
    "        headers (dict): A python dictionary containing HTTP headers including Authentication to be sent\n",
    "        url_params (dict): The parameters (required and optional) supported by endpoint\n",
    "        \n",
    "    Returns:\n",
    "        results (json): response as json\n",
    "    \"\"\"\n",
    "    # See requests.request?\n",
    "    response = [YOUR CODE HERE]\n",
    "    return [YOUR CODE HERE]\n",
    "    \n",
    "\n",
    "def spotify_search(client_id, client_secret, **kwargs):\n",
    "    \"\"\"\n",
    "    Make an authenticated request to the Spotify API and return search results.\n",
    "\n",
    "    Args:\n",
    "        client_id (string): Your Spotify Client ID for Authentication\n",
    "        client_secret (string): Your Spotify Client Secret for Authentication\n",
    "        **kwargs: Additional search parameters (e.g., artist, track, album, etc.)\n",
    "\n",
    "    Returns:\n",
    "        total (integer): Total number of tracks matching the query\n",
    "        tracks (list): List of dicts representing each track with name, and popularity\n",
    "    \"\"\"\n",
    "    url, headers, params = spotify_search_params(client_id, client_secret, **kwargs)\n",
    "    response_json = api_get_request(url, headers, params)\n",
    "    total = response_json['tracks']['total']\n",
    "    tracks = []\n",
    "    if response_json['tracks']['items']:\n",
    "            popularities = []\n",
    "            for track in response_json['tracks']['items']:\n",
    "                track_info = {\n",
    "                    'track_name': track['name'],\n",
    "                    'popularity': track['popularity']\n",
    "                }\n",
    "                tracks.append(track_info)\n",
    "                popularities.append(track['popularity'])\n",
    "            \n",
    "    return total, tracks\n",
    "\n",
    "# 2% credit\n",
    "total, tracks = spotify_search(client_id, client_secret,artist=\"Taylor Swift\", track=\"Lover\", type=\"track\", limit=5)\n",
    "print(total)\n",
    "#35\n",
    "print(tracks)\n",
    "#[{'track_name': 'Lover', 'popularity': 86}, {'track_name': 'Lover (Remix) [feat. Shawn Mendes]', 'popularity': 66}, {'track_name': 'Lover - First Dance Remix', 'popularity': 53}, {'track_name': 'Lover - Live From Paris', 'popularity': 49}, {'track_name': 'Lover', 'popularity': 17}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed the \"hello world\" of working with the Spotify API, we are ready to really fly! The rest of the exercise will have a bit less direction since there are a variety of ways to retrieve the requested information but you should have all the component knowledge at this point to work with the API.\n",
    "\n",
    "## Parameterization and Pagination\n",
    "\n",
    "Before we can retrieve all of Taylor Swift's tracks, albums, or playlists, we need to understand how to work with the Spotify API's search and pagination system. Spotify's API returns a limited number of results per request to safeguard against returning TOO much data at once (imagine if you were to request 100,000 tracks in one go!). This limitation is common among APIs and helps manage rate limiting while ensuring efficient and fair access to Spotify's vast music database.\n",
    "\n",
    "> As a thought exercise, consider: If an API has 1,000,000 records, but only returns 10 records per page and limits you to 5 requests per second... how long will it take to acquire ALL of the records contained in the API?\n",
    "\n",
    "One of the ways that APIs are an improvement over plain web scraping is the ability to make __parameterized__ requests. Just like the Python functions you have been writing have arguments (or parameters) that allow you to customize its behavior/actions (an output) without having to rewrite the function entirely, we can parameterize the queries we make to the Spotify API to filter the results it returns.\n",
    "\n",
    "### Question 2.3: Retrieve All Tracks by Taylor Swift on Spotify (10%)\n",
    "\n",
    "Again using the [API documentation](https://developer.spotify.com/documentation/web-api/reference/get-track) for the `search` endpoint, fill in the following function to retrieve all of the _Tracks_ for a given query. Again you should use your `read_api_key()` function to read the API Key used for the requests. You will need to account for __pagination__ and __[rate limiting](https://developer.spotify.com/documentation/web-api/concepts/rate-limits)__ to:\n",
    "\n",
    "1. Retrieve all of the Track objects (# of track objects should equal `total` in the response). **Paginate by querying 10 restaurants each request.**\n",
    "2. Pause slightly (at least 200 milliseconds) between subsequent requests so as to not overwhelm the API (and get blocked).  \n",
    "\n",
    "As always with API access, make sure you follow all of the [API's policies](https://developer.spotify.com/documentation/web-api/concepts/rate-limits) and use the API responsibly and respectfully.\n",
    "\n",
    "**DO NOT MAKE TOO MANY REQUESTS TOO QUICKLY OR YOUR KEY MAY BE BLOCKED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4% credit\n",
    "def paginated_spotify_search_requests(client_id, client_secret, artist_name, total,limit):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples (url, headers, params) for paginated search of all restaurants\n",
    "    Args:\n",
    "        client_id, client_secret (string): Your Spotify API Key for Authentication\n",
    "        artist_name (string): Artist name\n",
    "        total (int): Total number of items to be fetched\n",
    "        limit (int): Number of items to fetch per request (default is 50)\n",
    "    Returns:\n",
    "        results (list): list of tuple (url, headers, params)\n",
    "    \"\"\"\n",
    "    # HINT: Use total, offset and limit for pagination\n",
    "    # You can reuse function location_search_params(...)\n",
    "    [YOUR CODE HERE]\n",
    "    \n",
    "#     return \n",
    "\n",
    "# Example Usage\n",
    "artist_name = \"Taylor Swift\"\n",
    "total=200\n",
    "limit=50\n",
    "all_track_requests = paginated_spotify_search_requests(client_id, client_secret, artist_name, total,limit)\n",
    "all_track_requests\n",
    "\n",
    "#[('https:<hidden>',\n",
    "#  {'Authorization': 'Bearer your_access_token'},\n",
    "#  {'q': 'artist:Taylor Swift', 'type': 'track', 'limit': 50, 'offset': 0}),\n",
    "# ('https:<hidden>',\n",
    "#  {'Authorization': 'Bearer your_access_token'},\n",
    "#  {'q': 'artist:Taylor Swift', 'type': 'track', 'limit': 50, 'offset': 50}),\n",
    "# ('https:<hidden>',\n",
    "#  {'Authorization': 'Bearer your_access_token'},\n",
    "#  {'q': 'artist:Taylor Swift', 'type': 'track', 'limit': 50, 'offset': 100}),\n",
    "# ('https:<hidden>',\n",
    "#  {'Authorization': 'Bearer your_access_token'},\n",
    "#  {'q': 'artist:Taylor Swift', 'type': 'track', 'limit': 50, 'offset': 150})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3% credit\n",
    "def get_tracks(client_id, client_secret, artist_name):\n",
    "    \"\"\"\n",
    "    Construct the pagination requests for ALL tracks by Given Artist on Spotify.\n",
    "\n",
    "    Args:\n",
    "        client_id (string): Your Spotify Client ID for Authentication\n",
    "        client_secret (string): Your Spotify Client Secret for Authentication\n",
    "        artist_name (string): Artist name\n",
    "\n",
    "    Returns:\n",
    "        results (list): List of dicts representing each track\n",
    "    \"\"\"\n",
    "    total_items = 200\n",
    "    limit = 50\n",
    "    \n",
    "    tracks_request = paginated_spotify_search_requests(api_key, location, total_items,limit)\n",
    "    \n",
    "    # Use returned list of (url, headers, url_params) and function api_get_request to retrive all restaurants\n",
    "    # REMEMBER to pause slightly after each request.\n",
    "    [YOUR CODE HERE]\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3% credit\n",
    "artist_name = 'Taylor Swift'\n",
    "data = get_tracks(client_id, client_secret, artist_name)\n",
    "print(len(data))\n",
    "# 200\n",
    "\n",
    "# Display first 10 tracks with Track name, Album name and Popularity\n",
    "[YOUR CODE HERE]\n",
    "\n",
    "# Track: Cruel Summer, Album: Lover, Popularity: 89\n",
    "# Track: august, Album: folklore, Popularity: 88\n",
    "# Track: Style, Album: 1989, Popularity: 76\n",
    "# Track: Don’t Blame Me, Album: reputation, Popularity: 84\n",
    "# Track: Lover, Album: Lover, Popularity: 86\n",
    "# Track: cardigan, Album: folklore, Popularity: 85\n",
    "# Track: Delicate, Album: reputation, Popularity: 83\n",
    "# Track: Blank Space, Album: 1989, Popularity: 75\n",
    "# Track: ...Ready For It?, Album: reputation, Popularity: 81\n",
    "# Track: Fortnight (feat. Post Malone), Album: THE TORTURED POETS DEPARTMENT, Popularity: 83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the metadata on 300 tracks of Taylor Swift on Spotify, we can retrieve the album cover images. For that we need to download from image links, but to find out what pages to download we first need to parse our JSON from the API to extract the URLs of the tracks.\n",
    "\n",
    "In general, it is a best practice to separate the act of __downloading__ data and __parsing__ data. This ensures that your data processing pipeline is modular and extensible (and autogradable ;). This decoupling also solves the problem of expensive downloading but cheap parsing (in terms of computation and time).\n",
    "\n",
    "### Question 2.4: Parse the API Responses and Extract the URLs (7%)\n",
    "\n",
    "Because we want to separate the __downloading__ from the __parsing__, fill in the following function to parse the URLs pointing to the tracks. As input your function should expect a string of [properly formatted JSON](http://www.json.org/) (which is similar to __BUT__ not the same as a Python dictionary) and as output should return a Python list of strings. Hint: print your `data` to see the JSON-formatted information you have. The input JSON will be structured as follows (same as the [sample](https://developer.spotify.com/documentation/web-api/reference/get-track) on the Spotify API page):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"album\": {\n",
    "    \"album_type\": \"compilation\",\n",
    "    \"total_tracks\": 9,\n",
    "    \"available_markets\": [\"CA\", \"BR\", \"IT\"],\n",
    "    \"external_urls\": {\n",
    "      \"spotify\": \"string\"\n",
    "    },\n",
    "    \"href\": \"string\",\n",
    "    \"id\": \"2up3OPMp9Tb4dAKM2erWXQ\",\n",
    "    \"images\": [\n",
    "      {\n",
    "        \"url\": \"https://i.scdn.co/image/ab67616d00001e02ff9ca10b55ce82ae553c8228\",\n",
    "        \"height\": 300,\n",
    "        \"width\": 300\n",
    "      }\n",
    "    ],\n",
    "    \"name\": \"string\",\n",
    "    \"release_date\": \"1981-12\",\n",
    "    \"release_date_precision\": \"year\",\n",
    "    \"restrictions\": {\n",
    "      \"reason\": \"market\"\n",
    "    },\n",
    "    \"type\": \"album\",\n",
    "    \"uri\": \"spotify:album:2up3OPMp9Tb4dAKM2erWXQ\",\n",
    "    \"artists\": [\n",
    "      {\n",
    "        \"external_urls\": {\n",
    "          \"spotify\": \"string\"\n",
    "        },\n",
    "        \"href\": \"string\",\n",
    "        \"id\": \"string\",\n",
    "        \"name\": \"string\",\n",
    "        \"type\": \"artist\",\n",
    "        \"uri\": \"string\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"artists\": [\n",
    "    {\n",
    "      \"external_urls\": {\n",
    "        \"spotify\": \"string\"\n",
    "      },\n",
    "      \"href\": \"string\",\n",
    "      \"id\": \"string\",\n",
    "      \"name\": \"string\",\n",
    "      \"type\": \"artist\",\n",
    "      \"uri\": \"string\"\n",
    "    }\n",
    "  ],\n",
    "  \"available_markets\": [\"string\"],\n",
    "  \"disc_number\": 0,\n",
    "  \"duration_ms\": 0,\n",
    "  \"explicit\": false,\n",
    "  \"external_ids\": {\n",
    "    \"isrc\": \"string\",\n",
    "    \"ean\": \"string\",\n",
    "    \"upc\": \"string\"\n",
    "  },\n",
    "  \"external_urls\": {\n",
    "    \"spotify\": \"string\"\n",
    "  },\n",
    "  \"href\": \"string\",\n",
    "  \"id\": \"string\",\n",
    "  \"is_playable\": false,\n",
    "  \"linked_from\": {\n",
    "  },\n",
    "  \"restrictions\": {\n",
    "    \"reason\": \"string\"\n",
    "  },\n",
    "  \"name\": \"string\",\n",
    "  \"popularity\": 0,\n",
    "  \"preview_url\": \"string\",\n",
    "  \"track_number\": 0,\n",
    "  \"type\": \"track\",\n",
    "  \"uri\": \"string\",\n",
    "  \"is_local\": false\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4% credit\n",
    "def parse_api_response(data):\n",
    "    \"\"\"\n",
    "    Parse Spotify API results to extract cover images URLs.\n",
    "    \n",
    "    Args:\n",
    "        data (string): String of properly formatted JSON.\n",
    "\n",
    "    Returns:\n",
    "        (list): list of URLs as strings from the input JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    [YOUR CODE HERE]\n",
    "\n",
    "# 3% credit    \n",
    "url, headers, params = spotify_search_params(\n",
    "    client_id, client_secret, \n",
    "    artist=\"Taylor Swift\", \n",
    "    track=\"Lover\", \n",
    "    type=\"track\",\n",
    "    limit=2,\n",
    "    offset=0\n",
    ")\n",
    "response_text = [YOUR CODE HERE]\n",
    "parse_api_response(response_text)\n",
    "\n",
    "#['https://i.scdn.co/image/ab67616d0000b273e787cffec20aa2a396a61647',\n",
    "# 'https://i.scdn.co/image/ab67616d00001e02e787cffec20aa2a396a61647',\n",
    "# 'https://i.scdn.co/image/ab67616d00004851e787cffec20aa2a396a61647',\n",
    "# 'https://i.scdn.co/image/ab67616d0000b27359457bdb1edb5c6417f3baa2',\n",
    "# 'https://i.scdn.co/image/ab67616d00001e0259457bdb1edb5c6417f3baa2',\n",
    "# 'https://i.scdn.co/image/ab67616d0000485159457bdb1edb5c6417f3baa2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, JSON is quite trivial to parse (which is not the case with HTML as we will see in a second) and work with programmatically. This is why it is one of the most ubiquitous data serialization formats (especially for ReSTful APIs) and a huge benefit of working with a well defined API if one exists. But APIs do not always exists or provide the data we might need, and as a last resort we can always scrape web pages...\n",
    "\n",
    "## Working with Web Pages (and HTML)\n",
    "\n",
    "Think of APIs as similar to accessing an application's database itself (something you can interactively query and receive structured data back). But the results are usually in a somewhat raw form with no formatting or visual representation (like the results from a database query). This is a benefit _AND_ a drawback depending on the end use case. For data science and _programatic_ analysis this raw form is quite ideal, but for an end user requesting information from a _graphical interface_ (like a web browser) this is very far from ideal since it takes some cognitive overhead to interpret the raw information. And vice versa, if we have HTML it is quite easy for a human to visually interpret it, but to try to perform some type of programmatic analysis we first need to parse the HTML into a more structured form.\n",
    "\n",
    "> As a general rule of thumb, if the data you need can be accessed or retrieved in a structured form (either from a bulk download or API) prefer that first. But if the data you want (and need) is not as in our case we need to resort to alternative (messier) means.\n",
    "\n",
    "We may like to scrape more information of tracks, such as lyrics. However, due to Spotify's API's policy, we are not able to scrape track pages. Always ensure you're using APIs and accessing data legally and ethically, respecting the terms of service of the platform you're working with.\n",
    "\n",
    "Going back to the \"hello world\" example of question 2.1 with the AP News, we will retrieve the HTML of the movie site to get more interesting information as text, such as storyline and reviews. \n",
    "\n",
    "\n",
    "### Question 2.5: Parse a Movie Page from imdb (11%)\n",
    "\n",
    "Using `BeautifulSoup`, parse the HTML of a single movie page to extract the reviews in a structured form as well as the URL to the next page of reviews (or `None` if it is the last page). Fill in following function stubs to parse a single page of reviews and return:\n",
    "* the reviews as a structured Python dictionary\n",
    "* the HTML element containing the link/url for the next page of reviews (or None).\n",
    "\n",
    "For each review be sure to structure your Python dictionary as follows (to be graded correctly). The order of the keys doesn't matter, only the keys and the data type of the values:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'Author': str\n",
    "    'Rating': float\n",
    "    'Date': str ('dd mm yyyy')\n",
    "    'Review': str\n",
    "}\n",
    "\n",
    "# Example\n",
    "{\n",
    "    'Author': 'ap_griffiths'\n",
    "    'Rating': 5\n",
    "    'Date': '24 January 2012'\n",
    "    'Review': \"This is not a bad film per se, had it been about 30-40 minutes shorter I would not have been too offended.\"\n",
    "}\n",
    "```\n",
    "\n",
    "There can be issues with Beautiful Soup using various parsers, for maximum compatibility (and fewest errors) initialize the library with the default (and Python standard library parser): `BeautifulSoup(markup, \"html.parser\")`.\n",
    "\n",
    "Most of the function has been provided to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_lookup = {\"https://www.imdb.com/title/tt1375666/reviews?ref_=tt_urv\":\"Inception.html\"}\n",
    "\n",
    "def html_fetcher(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        status_code (integer):\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    html_file = url_lookup.get(url)\n",
    "    with open(html_file, 'rb') as file:\n",
    "        html_text = file.read()\n",
    "        return 200, html_text\n",
    "\n",
    "\n",
    "def parse_page(html):\n",
    "    \"\"\"\n",
    "    Parse reviews from an IMDb movie reviews page.\n",
    "\n",
    "    Args:\n",
    "        html (string): HTML content of the IMDb reviews page.\n",
    "\n",
    "    Returns:\n",
    "        reviews (list): A list of dictionaries, each containing the review's rating, author, date, and content.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    reviews_list = []\n",
    "\n",
    "    # Find all review containers on the page\n",
    "    review_containers = soup.find_all('div', class_='lister-item-content')\n",
    "    # HINT: print reviews to see what http tag to extract\n",
    "    [YOUR CODE HERE]\n",
    "        \n",
    "    return reviews_list\n",
    "\n",
    "# Example Usage\n",
    "code, html = html_fetcher(\"https://www.imdb.com/title/tt1375666/reviews?ref_=tt_urv\") #should load inception movie released in 2010\n",
    "reviews_list = parse_page(html)\n",
    "print(len(reviews_list)) # 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (10% of HW 1): Basic Probability (Refer to tutorial noteboook on Piazza for definition)\n",
    "\n",
    "Now we will answer some basic probability questions. You may type the answers using markdown or attach photos of your answers using $\\text{![](image.png)}$ where image has your answers. \n",
    "\n",
    "1. (5% credit) Let $X$ and $Y$ be random variables with the following joint distribution:\n",
    "\n",
    "    <center>\n",
    "\n",
    "    |    $\\mathbb{P}(X=x,Y=y)$ | X=1 | X=2|X=3|X=4|\n",
    "    | -------- | ------- | ------- | ------- | ------- |\n",
    "    |Y=0|1/18|1/18|1/9|1/9|\n",
    "    |Y=1|1/12|1/12|1/6|1/15|\n",
    "    |Y=2|1/15|1/30|1/30|2/15|\n",
    "\n",
    "    </center>\n",
    "    Answer the following questions:\n",
    "    \n",
    "    1. What are the marginal distributions of $X$ and $Y$?\n",
    "        \n",
    "    2. Are $X$ and $Y$ independent? Justify your answer.\n",
    "\n",
    "    3. What is the conditional distribution of $X$, given that $Y=2$? What is $\\mathbb{E}\\left[X|Y=2\\right]$?\n",
    "\n",
    "    4. Calculate $\\mathbb{E}[Y]$ and $\\mathbb{E}[XY]$.\n",
    "\n",
    "2. (5% credit) A coin is tossed three times with probability of heads p. Consider the following four events:\n",
    "\n",
    "    A: Heads on the first toss\n",
    "    \n",
    "    B: Heads on the second toss\n",
    "    \n",
    "    C: All three outcomes the same\n",
    "    \n",
    "    D: Exactly two heads\n",
    "\n",
    "    Which of the following pairs of events are independent? (More than one pair may be independent.) Justify your answer.\n",
    "    \n",
    "    1. A and B; 2. A and C; 3. A and D; 4. C and D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Submission\n",
    "\n",
    "You're almost done! \n",
    "\n",
    "After executing all commands and completing this notebook, save your *cs418-hw1-F25.ipynb* as a pdf file and upload it to Gradescope under *Homework 1 (written)*. Make sure you check that your pdf file includes all parts of your solution **(including the outputs)**. We recommend using the browser (not jupyter) for saving the pdf. For Chrome on a Mac, this is under *File->Print...->Open PDF in Preview* and when the PDF opens in Preview you can use *Save...* to save it. This part will be graded based on completion (having executed the code and showing the output).\n",
    "\n",
    "Next, you need to copy the functions from Questions 1.2 and 1.3 into the corresponding functions in *hw1part1.py*. Similarly, you need to copy the functions from Questions 2.1, 2.2, 2.3, 2.4, and 2.5 into the corresponding functions in *hw1part2.py*. Place your files *hw1part1.py*, *hw1part2.py*, and *cs418-hw1-F25.ipynb* in a zip file and upload the zip file to Gradescope under *Homework 1 - (code)*. In order to get full points for this part, you need to pass all test cases that we will run against your *hw1part1.py* and *hw1part2.py* (and not the notebook) on Gradescope. We have provided a sample of the test cases in *tests_sample_part1/tests.py* and *tests_sample_part2/tests.py*. Other tests are hidden on the Gradescope server. To check whether your code runs locally, run the four tests in *tests_sample_part1* from your command line: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(cs418-fa25) sathya@Sathyas-MacBook-Pro h1% python run_tests_sample.py part1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "You should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "....\n",
    "----------------------------------------------------------------------\n",
    "Ran 4 tests in 0.001s\n",
    "\n",
    "OK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add more tests that check all parts of your code.\n",
    "\n",
    "Similarly, you can run sample tests for part2 as follows:\n",
    "\n",
    "`(cs418-fa25) sathya@Sathyas-MacBook-Pro h1% python run_tests_sample.py part2`\n",
    "\n",
    "However, for part2 test to work you need to edit the test cases code in tests_sample_part2/tests.py and add you individual client_id and client_secret.\n",
    "\n",
    "You can submit to Gradescope as many times as you would like. We will only consider your last submission. If your last submission is after the deadline, the late homework policy applies.\n",
    "\n",
    "After submitting the zip file, the autograder will run. If you see a screen after the autograder finishes the execution with all correct, then it means that all the tests ran successfully on the server, and you're done! If your tests fail, you can debug your program locally by comparing the input, output and expected output (as shown for first two test cases)..\n",
    "\n",
    "Make sure `hw1part1.py`, `hw1part2.py` and `cs418-hw1-F25.ipynb` are included on the root of the zip file. **This means you need to zip those files and not the folder containing the files.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
